{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import rioxarray as rioxr\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'inputDirectory':'',\n",
    " 'outputDirectory':'',         \n",
    " 'bands':[1,2,3],\n",
    " 'sizeCutOut':20,\n",
    " 'nEpochMax':2,\n",
    " 'sizeStep':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_list(inputDir):\n",
    "    inputList = [t for t in pathlib.Path(inputDir).glob('*.tif')]\n",
    "    return inputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config):\n",
    "    if pathlib.Path(config).is_file():\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    else :\n",
    "        inputDir = config['inputDirectory']\n",
    "        outputDir = config['outputDirectory']\n",
    "        bands = config['bands']\n",
    "        sizeCutOut = config['sizeCutOut']\n",
    "        nEpochMax = config['nEpochMax']\n",
    "        sizeStep = config['sizeStep']\n",
    "        \n",
    "    return inputDir, outputDir, bands, sizeCutOut, nEpochmax, sizeStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define Dataset class and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, tile_list, cutout_size, bands, offset=0, stride=None, num_tiles=None, shuffle_tiles=False):\n",
    "        self.cutout_size = cutout_size\n",
    "        self.bands = bands\n",
    "        self.stride = stride if stride is not None else self.cutout_size\n",
    "        _num_tiles = num_tiles if num_tiles is not None else len(tile_list)\n",
    "        self.tiles = random.sample(tile_list, _num_tiles) if shuffle_tiles else tile_list[:_num_tiles]\n",
    "        if offset >= cutout_size:\n",
    "            raise ValueError(\n",
    "                \"offset larger than window size - set \"\n",
    "                \"offset to {}\".format(sizeCutOut%offset)\n",
    "            )\n",
    "        self.offset = offset\n",
    "        \n",
    "        self.mask = None\n",
    "        self.buffer = None\n",
    "        self.invert = None\n",
    "        self.all_touched = None\n",
    "    \n",
    "    def set_mask(self, geometry, crs, buffer=None, invert=False, all_touched=False):\n",
    "        \"\"\" Mask a selection of the pixels using a geometry.\"\"\"\n",
    "        self.mask = gpd.GeoSeries({\"geometry\": geometry}, crs=crs)\n",
    "        self.buffer = buffer if buffer is not None else 0\n",
    "        self.invert = invert\n",
    "        self.all_touched = all_touched\n",
    "    \n",
    "    def to_tf(self):\n",
    "        \"\"\" Obtain dataset as a tensorflow `Dataset` object. \"\"\"\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            self._generate_cutouts,  \n",
    "            output_types=(tf.float64, tf.float64, tf.float32), \n",
    "            output_shapes=(\n",
    "                None,  # x\n",
    "                None,  # y\n",
    "                (None, None, self.cutout_size, self.cutout_size)  # samples, bands, x_win, y_win\n",
    "            )\n",
    "        )\n",
    "        return ds.flat_map(lambda x,y,z: tf.data.Dataset.from_tensor_slices((x,y,z)))\n",
    "\n",
    "    def _generate_cutouts(self):\n",
    "        \"\"\" \n",
    "        Iterate over (a selection of) the tiles yielding all \n",
    "        cutouts for each of them.\n",
    "        \"\"\"\n",
    "        for tile in self.tiles:\n",
    "            \n",
    "            print(f\"Reading tile {tile}!\")\n",
    "            \n",
    "            # read tile\n",
    "            da = rioxr.open_rasterio(tile).astype(\"float32\")  # needed to mask with NaN's\n",
    "            \n",
    "            #select bands\n",
    "            if self.bands is not None:\n",
    "                if type(self.bands) is not list:\n",
    "                    da = da.sel(band=[self.bands])\n",
    "                else:\n",
    "                    da = da.sel(band=self.bands)\n",
    "                    \n",
    "                \n",
    "            \n",
    "            if self.mask is not None:\n",
    "                mask = self.mask.to_crs(da.spatial_ref.crs_wkt)\n",
    "                geometry = mask.unary_union.buffer(self.buffer)\n",
    "                da = da.rio.clip([geometry], drop=True, invert=self.invert, all_touched=self.all_touched)\n",
    "            \n",
    "            # apply offset\n",
    "            da = da.shift(x=self.offset, y=self.offset)  # only shift data, not coords\n",
    "            da['x'] = da.x.shift(x=self.offset)\n",
    "            da['y'] = da.y.shift(y=self.offset)\n",
    "\n",
    "            # generate windows\n",
    "            da = da.rolling(x=self.cutout_size, y=self.cutout_size)\n",
    "            da = da.construct({'x': 'x_win', 'y': 'y_win'}, stride=self.stride)\n",
    "\n",
    "            # drop NaN-containing windows\n",
    "            da = da.stack(sample=('x', 'y'))\n",
    "            da = da.dropna(dim='sample', how='any')\n",
    "            yield (da.sample.coords['x'], \n",
    "                   da.sample.coords['y'], \n",
    "                   da.data.transpose(3, 1, 2, 0))  # samples, x_win, y_win, bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin feedloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir, outputDir, _, sizeCutOut, nEpochmax, sizeStep = read_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputList = create_input_list(inputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochCounter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"ne_10m_antarctic_ice_shelves_polys/ne_10m_antarctic_ice_shelves_polys.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epochcounter < nEpochsMax:\n",
    "    offset = epochcounter*sizeStep\n",
    "    #randomly permutate inputList for each epoch\n",
    "    #inputList = list(np.random.permutation(inputList))\n",
    "    #construct Dataset\n",
    "    inData = Dataset(inputList,sizeCutOut,offset=offset,shuffle_tiles=True)\n",
    "    inData.set_mask(gdf.unary_union, crs=gdf.crs)\n",
    "    dataSet = inData.to_tf()\n",
    "    \n",
    "    \"\"\"\n",
    "    this buffersize sould correpond to 6 full tiles, \n",
    "    so 7 in total in memory\n",
    "    \"\"\" \n",
    "    dataSet.shuffle(buffersize=3000000).batch(64,drop_remainder=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    network to be addded below\n",
    "    \"\"\"\n",
    "    #network here\n",
    "       #input\n",
    "        \n",
    "       #save network\n",
    "       #outputDir has been specified in config\n",
    "        \n",
    "       #early stopping ?\n",
    "    \n",
    "    #repeat from here\n",
    "        \n",
    "    epochcounter+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ice]",
   "language": "python",
   "name": "conda-env-ice-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
