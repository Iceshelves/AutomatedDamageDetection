{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build format VAE network\n",
    "Test VAE build before including it in larger training framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Install tensorflow:\n",
    "``%pip install tensorflow``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_encoder():    \n",
    "#     #filter_1 = 3 #32\n",
    "#     #filter_2 = 2 #64\n",
    "#     #kernel_size = 5 #3\n",
    "#     dense_size = 16; \n",
    "#     encoder_inputs = keras.Input(shape=(20, 20,3)) # enter cut-out shape (20,20,3)\n",
    "#     x = layers.Conv2D(filter_1, kernel_size, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "#     x = layers.Conv2D(filter_2, kernel_size, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "#     x = layers.Flatten()(x) # to vector\n",
    "#     x = layers.Dense(dense_size, activation=\"relu\")(x) # linked layer\n",
    "#     z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "#     z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "#     z = Sampling()([z_mean, z_log_var])\n",
    "#     encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "#     encoder.summary()\n",
    "#     return encoder_inputs, encoder, z , z_mean, z_log_var\n",
    "\n",
    "\n",
    "def make_encoder(cutout_size,n_bands,\n",
    "                 filter_1,filter_2,\n",
    "                 kernel_size_1,kernel_size_2,\n",
    "                 dense_size,latent_dim):    \n",
    "    encoder_inputs = keras.Input(shape=(cutout_size, cutout_size,n_bands)) # enter cut-out shape (20,20,3)\n",
    "    x = layers.Conv2D(filter_1, kernel_size_1, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "    x = layers.Conv2D(filter_2, kernel_size_2, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filter_2, kernel_size_2, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Flatten()(x) # to vector\n",
    "    x = layers.Dense(dense_size, activation=\"relu\")(x) # linked layer\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    encoder.summary()\n",
    "    \n",
    "    return encoder_inputs, encoder, z , z_mean, z_log_var\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_decoder(): \n",
    "#     latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "#     x = layers.Dense(5 * 5 * filter_2, activation=\"relu\")(latent_inputs) # -- shape corresponding to encoder\n",
    "#     x = layers.Reshape((5, 5, filter_2))(x)\n",
    "#     x = layers.Conv2DTranspose(filter_2, kernel_size, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "#     x = layers.Conv2DTranspose(filter_1, kernel_size, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "#     decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x) # (1,3) or (3,3)\n",
    "#     decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "#     decoder.summary()\n",
    "#     return decoder\n",
    "\n",
    "def make_decoder(latent_dim,encoder,\n",
    "                 filter_1,filter_2,\n",
    "                 kernel_size_1,kernel_size_2): \n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    # get shape of last layer in encoder before flattning\n",
    "    flat_layer = [layer for layer in encoder.layers if 'flatten' in layer.name] \n",
    "    flat_input = flat_layer[-1].input_shape # input shape of flat layer to be used to reconstruct; (None, 5,5,16) or smth\n",
    "    # x = layers.Dense(5 * 5 * filter_2, activation=\"relu\")(latent_inputs) # -- shape corresponding to encoder\n",
    "    # x = layers.Reshape((5, 5, filter_2))(x)\n",
    "    x = layers.Dense(flat_input[1] * flat_input[2] * filter_2, activation=\"relu\")(latent_inputs) # -- shape corresponding to encoder\n",
    "    x = layers.Reshape((flat_input[1], flat_input[2], filter_2))(x)\n",
    "    x = layers.Conv2DTranspose(filter_2, kernel_size_2, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(filter_2, kernel_size_2, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(filter_1, kernel_size_1, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x) # (1,3) or (3,3)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    decoder.summary()\n",
    "    return decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VAE as model\n",
    "With custom train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update: instead of defining VAE as class, use function-wise definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VAE model.\n",
    "def make_vae(encoder_inputs, z, z_mean, z_log_var, decoder,alpha=5):\n",
    "    outputs = decoder(z)\n",
    "    vae = tf.keras.Model(inputs=encoder_inputs, outputs=outputs, name=\"vae\")\n",
    "\n",
    "    # Add KL divergence regularization loss.\n",
    "    reconstruction = decoder(z)\n",
    "    reconstruction_loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            keras.losses.binary_crossentropy(encoder_inputs, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "    kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "#     alpha = 5\n",
    "\n",
    "    # Play witht different alpha: -2, 0 , 1 ,2 ; 0.2 ; -0.5 ; 50\n",
    "    # alpha = 10.; \n",
    "    total_loss = reconstruction_loss +  alpha * kl_loss # alpha is custom\n",
    "    vae.add_loss(total_loss)\n",
    "    return vae\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_59 (InputLayer)          [(None, 300, 300, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 150, 150, 32  2432        ['input_59[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 75, 75, 16)   12816       ['conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 75, 75, 16)   6416        ['conv2d_92[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_32 (Flatten)           (None, 90000)        0           ['conv2d_93[0][0]']              \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 16)           1440016     ['flatten_32[0][0]']             \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 4)            68          ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 4)            68          ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_32 (Sampling)         (None, 4)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,461,816\n",
      "Trainable params: 1,461,816\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(None, 75, 75, 16) (None, 90000)\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_60 (InputLayer)       [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 90000)             450000    \n",
      "                                                                 \n",
      " reshape_26 (Reshape)        (None, 75, 75, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_99 (Conv2D  (None, 75, 75, 16)       6416      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_100 (Conv2  (None, 150, 150, 16)     6416      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_101 (Conv2  (None, 300, 300, 32)     12832     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_102 (Conv2  (None, 300, 300, 3)      867       \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 476,531\n",
      "Trainable params: 476,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter1 = 32 \n",
    "filter2 = 16\n",
    "kernelSize1 = 5\n",
    "kernelSize2=kernelSize1\n",
    "denseSize = 16\n",
    "\n",
    "sizeCutOut=300\n",
    "bands = 3, 2, 1 \n",
    "\n",
    "latentDim = 4\n",
    "\n",
    "encoder_inputs, encoder, z, z_mean, z_log_var = make_encoder(\n",
    "                            sizeCutOut,len(bands),\n",
    "                            filter1,filter2,\n",
    "                            kernelSize1,kernelSize2,\n",
    "                            denseSize,latentDim)\n",
    "\n",
    "\n",
    "# for layer in encoder.layers:\n",
    "    # print(layer.name)\n",
    "    # print(layer.input_shape)\n",
    "    \n",
    "# layer_flatten_shape = encode\n",
    "# print(encoder.layers)\n",
    "flat_layer = [layer for layer in encoder.layers if 'flatten' in layer.name] # want flat_layer input_shape to usee in decoder\n",
    "dense_layer = [layer for layer in encoder.layers if 'dense' in layer.name]\n",
    "print(flat_layer[-1].input_shape,dense_layer[-1].input_shape)\n",
    "# print(encoder_inputs)\n",
    "decoder = make_decoder(latentDim,encoder,\n",
    "                       filter1,filter2,\n",
    "                       kernelSize1,kernelSize2)\n",
    "# vae = make_vae(encoder_inputs, z, z_mean, z_log_var, decoder)\n",
    "# # vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_42 (InputLayer)          [(None, 20, 20, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 10, 10, 64)   4864        ['input_42[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 5, 5, 32)     51232       ['conv2d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 5, 5, 32)     25632       ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_21 (Flatten)           (None, 800)          0           ['conv2d_49[0][0]']              \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 16)           12816       ['flatten_21[0][0]']             \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 4)            68          ['dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 4)            68          ['dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_21 (Sampling)         (None, 4)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 94,680\n",
      "Trainable params: 94,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 800)               4000      \n",
      "                                                                 \n",
      " reshape_20 (Reshape)        (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_65 (Conv2D  (None, 5, 5, 32)         25632     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_66 (Conv2D  (None, 10, 10, 32)       25632     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_67 (Conv2D  (None, 20, 20, 64)       51264     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_68 (Conv2D  (None, 20, 20, 3)        1731      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,259\n",
      "Trainable params: 108,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# test 0 works:\n",
    "# filter1 = 64 \n",
    "# filter2 = 16 \n",
    "# kernelSize = 5\n",
    "# denseSize = 16\n",
    "\n",
    "\n",
    "# # this did not work (out of memory)\n",
    "# filter1 = 128 \n",
    "# filter2 = 32 \n",
    "# kernelSize1 = 8\n",
    "# kernelSize2= 5\n",
    "# denseSize = 16\n",
    "\n",
    "filter1 = 64 \n",
    "filter2 = 32 \n",
    "kernelSize1 = 5\n",
    "kernelSize2= 5\n",
    "denseSize = 16\n",
    "\n",
    "sizeCutOut=20\n",
    "bands = 3, 2, 1 \n",
    "\n",
    "latentDim = 4\n",
    "\n",
    "encoder_inputs, encoder, z, z_mean, z_log_var = make_encoder(\n",
    "                            sizeCutOut,len(bands),\n",
    "                            filter1,filter2,\n",
    "                            kernelSize1,kernelSize2,\n",
    "                            denseSize,latentDim)\n",
    "\n",
    "decoder = make_decoder(latentDim,filter1,filter2,kernelSize1,kernelSize2)\n",
    "vae = make_vae(encoder_inputs, z, z_mean, z_log_var, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# number of training steps in 1 epoch \n",
    "model.fit( steps_per_epoch=None):  When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined\n",
    "\n",
    "So I have  204,259 samples (window size =100 )\n",
    "batch_size = 32 (default; do not set it yourself when using tf.datasets\n",
    "Number of steps: 2766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.84634851771511"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "204259 / 32\n",
    "204259 / 2766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
