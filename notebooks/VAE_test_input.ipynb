{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read tiles to input format VAE network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Install tensorflow:\n",
    "``%pip install tensorflow``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 20, 20, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 10, 10, 32)   896         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 5, 5, 64)     18496       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1600)         0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           25616       flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_4 (Sampling)           (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 45,076\n",
      "Trainable params: 45,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "encoder_inputs = keras.Input(shape=(20, 20,3)) # enter cut-out shape (20,20,3)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x) # to vector\n",
    "x = layers.Dense(16, activation=\"relu\")(x) # linked layer\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1600)              4800      \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DT (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DT (None, 20, 20, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT (None, 20, 20, 3)         867       \n",
      "=================================================================\n",
      "Total params: 61,059\n",
      "Trainable params: 61,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(5 * 5 * 64, activation=\"relu\")(latent_inputs) # -- shape corresponding to encoder\n",
    "x = layers.Reshape((5, 5, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VAE as model\n",
    "With custom train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (70000, 28, 28)\n",
      "<class 'numpy.ndarray'> (70000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# (x_train, _), (x_test, _) = keras.datasets.mnist.load_data() # reads data as numpy.ndarray\n",
    "\n",
    "# mnist_digits = np.concatenate([x_train, x_test], axis=0) # [70000,28,28]\n",
    "# print(type(mnist_digits), np.shape(mnist_digits))\n",
    "\n",
    "# mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255  # adds 4th dimension (bands) [70000,28,28,1]\n",
    "# print(type(mnist_digits),np.shape(mnist_digits))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stored cut-outs\n",
    "The VAE reads the example mnist data as ndarray. Therefore: read our cut-outs to np.ndarray\n",
    "\n",
    "#### List cut-out files on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "imPath = '/Users/maaikeizeboud/Documents/Data/tiles_test/'\n",
    "imgs = sorted([file for file in os.listdir(imPath) if file.endswith('.tif') ]) # list with image names\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import using rasterio\n",
    "Importing the .tif images using the keras ``load_img`` functions doesnt work well because it uses Pillow, which has trouble with .tif/.tiff.\n",
    "\n",
    "The .tif files are read to numpy.ndarray in the NCHW format (bands,rows,cols). Conv2DCustomBackpropInputOp only supports NHWC (Batch Size, Height of the Image, Width of the Image and Number of Channels), so reshape data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "\n",
    "# get tile size information to initialise ndarray \n",
    "with rasterio.open(imPath + imgs[0]) as src:\n",
    "#     imShape = [src.count, src.width, src.height] # returns ( bands , rows , cols)\n",
    "    imShape = [src.width, src.height,src.count]  # returns ( rows , cols, bands)\n",
    "# initialise ndarray    \n",
    "images = np.expand_dims( np.empty(imShape) , 0).astype(\"float32\"); # expand to 4th dimension to stack all images\n",
    "\n",
    "# load cut-outs\n",
    "for i in imgs:\n",
    "    with rasterio.open(imPath + i) as src:\n",
    "        imArray = src.read([1,2,3]) # reads all bands (expected 3 or 4) , returns np.ndarray (bands,rows,cols)\n",
    "        imArray = reshape_as_image(imArray) # reshapes to (rows,cols,bands)\n",
    "        imArray = np.expand_dims(imArray, 0).astype(\"float32\")  # ( bands , rows , cols, 1)\n",
    "        images = np.concatenate((images, imArray),axis=0) # stack data\n",
    "        \n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 41ms/step - loss: nan - reconstruction_loss: nan - kl_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c295f3460>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = mnist_digits #[70000,28,28,1]\n",
    "data = images; #[1001,3,20,20]\n",
    "\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "vae.fit(data, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display grid of sampled digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def plot_latent_space(vae, n=30, figsize=15):\n",
    "#     # display a n*n 2D manifold of digits\n",
    "#     digit_size = 28\n",
    "#     scale = 1.0\n",
    "#     figure = np.zeros((digit_size * n, digit_size * n))\n",
    "#     # linearly spaced coordinates corresponding to the 2D plot\n",
    "#     # of digit classes in the latent space\n",
    "#     grid_x = np.linspace(-scale, scale, n)\n",
    "#     grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "#     for i, yi in enumerate(grid_y):\n",
    "#         for j, xi in enumerate(grid_x):\n",
    "#             z_sample = np.array([[xi, yi]])\n",
    "#             x_decoded = vae.decoder.predict(z_sample)\n",
    "#             digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "#             figure[\n",
    "#                 i * digit_size : (i + 1) * digit_size,\n",
    "#                 j * digit_size : (j + 1) * digit_size,\n",
    "#             ] = digit\n",
    "\n",
    "#     plt.figure(figsize=(figsize, figsize))\n",
    "#     start_range = digit_size // 2\n",
    "#     end_range = n * digit_size + start_range\n",
    "#     pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "#     sample_range_x = np.round(grid_x, 1)\n",
    "#     sample_range_y = np.round(grid_y, 1)\n",
    "#     plt.xticks(pixel_range, sample_range_x)\n",
    "#     plt.yticks(pixel_range, sample_range_y)\n",
    "#     plt.xlabel(\"z[0]\")\n",
    "#     plt.ylabel(\"z[1]\")\n",
    "#     plt.imshow(figure, cmap=\"Greys_r\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display latent space clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_label_clusters(vae, data, labels):\n",
    "#     # display a 2D plot of the digit classes in the latent space\n",
    "#     z_mean, _, _ = vae.encoder.predict(data)\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel(\"z[0]\")\n",
    "#     plt.ylabel(\"z[1]\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "# x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "# plot_label_clusters(vae, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
